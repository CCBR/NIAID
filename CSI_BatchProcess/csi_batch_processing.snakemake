#################################
#
# snakefile for converting CIDR Sequencing data deliveries to non-PII ready for GRIS upload
#
# Susan Huse, susan.huse@nih.gov
# Frederick National Lab
# April 10, 2019
#
#################################

## 
## Load python modules
##
import os
from os import listdir
from os.path import join
import pandas as pd
import re
import sys
from glob import glob
import datetime

##
## Set initial global variables
##
dir_renamed = os.getcwd()
dir_rawdata = join(dir_renamed, "rawdata")
dir_hla_master = "/sysapps/cluster/software/HLA-LA/1.0/HLA-LA-master"
batch_number = re.sub("^.*BATCH","",dir_renamed)
batch_name = "BATCH" + batch_number
if int(batch_number) < 10:
    batch_name0 = "BATCH0" + batch_number
else:
    batch_name0 = "BATCH" + batch_number
    
dir_rawvcf = join(dir_rawdata, "MultiSampleVCF", "withGenotypeRefinement")
VCF = [f for f in os.listdir(dir_rawvcf) if re.match(r'.*.vcf.gz$', f)][0]
VCF = join(dir_rawvcf, VCF)
fnames = ["cumulative_coverage_counts", "cumulative_coverage_proportions", "gene_summary", "interval_statistics", "interval_summary", "statistics", "summary"]

## Check if these are bams or crams
if os.path.isdir(os.path.join(dir_rawdata, "CRAM")):
    seqdir = "CRAM"
    seqfile = "cram"
elif os.path.isdir(os.path.join(dir_rawdata, "BAM")):
    seqdir = "BAM"
    seqfile = "bam"
else:
    print("Unable to locate input rawdata BAM or CRAM folder.  Quitting.")
    sys.exit()


## Set variables for rerunning all of the old pedigrees
last_batch = str(int(batch_number) - 1)
dir_peds = "/hpcdata/dir/CIDR_DATA_RENAMED/pedigrees_updated"
todays_date = re.sub('-','',str(datetime.datetime.today()).split()[0])

##
## Read in the masterkey file 
##
#print(listdir(os.getcwd()))
df = pd.read_csv("masterkey_batch"+batch_number + ".txt", header=0, sep='\t')
df = df.loc[(df['Batch_Received'].isin([batch_name0, ""])) | (df['Batch_Received'].isnull())]
dict_CIDR = dict(zip(df['Phenotips_ID'].tolist(), df['CIDR_Exome_ID'].tolist()))
print(dict_CIDR)
#exit


##
## Set rule all
##
rule all:
    input: 
        bam = expand(join(dir_renamed, "BAM", "{newID}.bam"), newID=list(dict_CIDR.keys())),
        vcf = join(dir_renamed, "VCF", batch_name + ".vcf.gz"),
        vci = join(dir_renamed, "VCF", batch_name + ".vcf.gz.tbi"),
        #target = expand(join(dir_renamed, "QC", "TARGET", "{newID}.TARGET.sample_{fname}.csv"), newID = list(dict_CIDR.keys()), fname=fnames),
        #ucsc = expand(join(dir_renamed, "QC", "UCSC", "{newID}.UCSC.sample_{fname}.csv"), newID = list(dict_CIDR.keys()), fname=fnames),
        #last_ped = join(dir_peds, todays_date, "seqr_ped_batch" + last_batch + ".txt"),
        #hla = expand(join(dir_renamed, "HLA", "{newID}", "hla", "R1_bestguess_G.txt"), newID = list(dict_CIDR.keys())),
        admix_plot = join(dir_renamed, "BATCH_QC", "admixture", "admixture_mqc.png"),
        plota = join(dir_renamed, "inbreeding", "Heterozygous_to_Homozygous_Ratio_mqc.png"),
        plotb = join(dir_renamed, "inbreeding", "Mean_Homozygous_Tract_Length_mqc.png"),
        segs = expand(join(dir_renamed, "CNV", "gatk", "genotyped_segments_{newID}.vcf"), newID = list(dict_CIDR.keys())),
        intervals = expand(join(dir_renamed, "CNV", "gatk", "genotyped_intervals_{newID}.vcf"), newID = list(dict_CIDR.keys())),
        annot1 = expand(join(dir_renamed, "CNV", "gatk", "{newID}", "{newID}.intervals.annotations.tsv"), newID = list(dict_CIDR.keys())),
        annot2 = expand(join(dir_renamed, "CNV", "gatk", "{newID}", "{newID}.segments.annotations.tsv"), newID = list(dict_CIDR.keys())),
        fixed_cnv = expand(join(dir_renamed, "CNV", "gatk", "{newID}", "{newID}_cnv.txt"), newID = list(dict_CIDR.keys())) 

###
### Estimate ethnic admixture plot
###
rule admixture:
    input: 
        vcf = join(dir_renamed, "VCF", batch_name + ".vcf.gz"),
    output: 
        filtvcf = temp(join(dir_renamed, "BATCH_QC", "admixture", "filtered.recode.vcf")),
        mergedvcf = temp(join(dir_renamed, "BATCH_QC", "admixture", "merged.knowns.vcf")),
        admixtable = join(dir_renamed, "BATCH_QC", "admixture", "admixture_table.tsv"),
    params: 
        batch = batch_name, 
        rname = "admixture"
    shell: 
        """set +u
           export TODAY=`date +"%Y%m%d"`
           mkdir -p BATCH_QC/admixture
           module load vcftools/0.1.15-goolf-1.7.20-Perl-5.22.2
           vcftools --gzvcf {input.vcf} --remove-indels --max-missing 1 --recode --recode-INFO-all --out BATCH_QC/admixture/filtered
           module purge
           module load uge
           module load GATK/3.7-0-Java-1.8.0_92
           java -Xmx12g -jar $EBROOTGATK/GenomeAnalysisTK.jar -T CombineVariants -R /hpcdata/dir/CIDR_DATA_RENAMED/references/human_g1k_v37_decoy.fasta --genotypemergeoption UNSORTED -o {output.mergedvcf} --variant {output.filtvcf} --variant /hpcdata/dir/software/resources/1k_genomes_phase3_autosomes.vcf.gz --minimumN 2 -nt 4
           module purge
           module load uge
           module load plink/1.90-x86_64-beta
           plink --noweb --recode12 --snps-only --maf 0.05 --out BATCH_QC/admixture/merged.filtered.knowns --vcf {output.mergedvcf}
           perl /hpcdata/dir/software/admixture_prep.pl /hpcdata/dir/software/resources/1k_genomes_superpop_key.txt BATCH_QC/admixture/merged.filtered.knowns.pop BATCH_QC/admixture/merged.filtered.knowns.ped
           /hpcdata/dir/software/admixture_linux-1.3.0/admixture BATCH_QC/admixture/merged.filtered.knowns.ped 5 --supervised -j4
           mv merged.filtered.knowns.5.P BATCH_QC/admixture/merged.filtered.knowns.5.P
           mv merged.filtered.knowns.5.Q BATCH_QC/admixture/merged.filtered.knowns.5.Q
           perl /hpcdata/dir/software/admixture_post.pl /hpcdata/dir/software/resources/1k_genomes_superpop_key.txt {output.admixtable} BATCH_QC/admixture/merged.filtered.knowns.5.Q hg19 BATCH_QC/admixture/merged.filtered.knowns.ped"""

###
### Plot ethnic admixture
###
rule admixplot:
    input: admixtable = join(dir_renamed, "BATCH_QC", "admixture", "admixture_table.tsv"),
    output: admix_plot = join(dir_renamed, "BATCH_QC", "admixture", "admixture_mqc.png"),
    params: rname = "admixplot"
    shell: 
        """set +u
        export TODAY=`date +"%Y%m%d"`
        module load R; Rscript /hpcdata/dir/software/admixplot.R"""


###
### CNV Calling
###
rule cnv_wes:
    input: 
        bam = join(dir_renamed, "BAM", "{newID}.bam")
    output: 
        segs = join(dir_renamed, "CNV", "gatk", "genotyped_segments_{newID}.vcf"),
        intervals = join(dir_renamed, "CNV", "gatk", "genotyped_intervals_{newID}.vcf"),
    params: 
        batch = batch_name, 
        rname = "cnv"
    shell: 
        """set +u
        export TODAY=`date +"%Y%m%d"` 
        /hpcdata/dir/software/gatk_cnvs_master.sh {wildcards.newID}"""

###
### CNV Post-processing
###
rule cnv_post:
    input: 
        vcf = join(dir_renamed, "VCF", batch_name + ".vcf.gz"),
        intervals = join(dir_renamed, "CNV", "gatk", "genotyped_intervals_{newID}.vcf"),
        segments = join(dir_renamed, "CNV", "gatk", "genotyped_segments_{newID}.vcf"),
    output: 
        reformat1 = temp(join(dir_renamed, "CNV", "gatk", "{newID}", "genotyped_intervals_{newID}.reformat.vcf")),
        reformat2 = temp(join(dir_renamed, "CNV", "gatk", "{newID}", "genotyped_segments_{newID}.reformat.vcf")),
        varintervals1 = temp(join(dir_renamed, "CNV", "gatk", "{newID}", "genotyped_intervals_{newID}.var.vcf")),
        varintervals2 = temp(join(dir_renamed, "CNV", "gatk", "{newID}", "genotyped_segments_{newID}.var.vcf")),
        cols1 = temp(join(dir_renamed, "CNV", "gatk", "{newID}", "{newID}.intervals.columns")),
        cols2 = temp(join(dir_renamed, "CNV", "gatk", "{newID}", "{newID}.segments.columns")),
        bed1 = temp(join(dir_renamed, "CNV", "gatk", "{newID}", "{newID}.intervals.bed")),
        bed2 = temp(join(dir_renamed, "CNV", "gatk", "{newID}", "{newID}.segments.bed")),
        annot1 = join(dir_renamed, "CNV", "gatk", "{newID}", "{newID}.intervals.annotations.tsv"),
        annot2 = join(dir_renamed, "CNV", "gatk", "{newID}", "{newID}.segments.annotations.tsv"),
        candidates = join(dir_renamed, "CNV", "gatk", "{newID}", "{newID}.candidate.cnvs"),
    params: 
        batch = batch_name, 
        rname = "cnv_post",
        sample = "{newID}"
    shell: 
        """set +u
           module load GATK/3.7-0-Java-1.8.0_92           
           mkdir -p CNV/gatk/{params.sample}
           java -Xmx12g -jar $EBROOTGATK/GenomeAnalysisTK.jar -T SelectVariants -R /hpcdata/dir/CIDR_DATA_RENAMED/references/human_g1k_v37_decoy.fasta -V {input.intervals} -L /hpcdata/dir/software/resources/GRCh37.chroms.bed -o {output.reformat1} -nt 4
           java -Xmx12g -jar $EBROOTGATK/GenomeAnalysisTK.jar -T SelectVariants -R /hpcdata/dir/CIDR_DATA_RENAMED/references/human_g1k_v37_decoy.fasta -V {input.segments} -L /hpcdata/dir/software/resources/GRCh37.chroms.bed -o {output.reformat2} -nt 4
           module load bcftools
           bcftools view -q 1 {output.reformat1} > {output.varintervals1}
           bcftools view -q 1 {output.reformat2} > {output.varintervals2}
           bcftools query -f '%CHROM\t%POS\t%END[\t%CN]\n' {output.varintervals1} > {output.cols1}
           bcftools query -f '%CHROM\t%POS\t%END[\t%CN]\n' {output.varintervals2} > {output.cols2}
           sed -i '1 i\#Chrom\tStartPosition\tEndPosition\tCopyNumber' {output.cols1}
           sed -i '1 i\#Chrom\tStartPosition\tEndPosition\tCopyNumber' {output.cols2}
           perl /hpcdata/dir/software/make_CNV_bed.pl {output.cols1} {output.bed1}
           perl /hpcdata/dir/software/make_CNV_bed.pl {output.cols2} {output.bed2}
           export ANNOTSV=/hpcdata/dir/software/AnnotSV_2.1
           $ANNOTSV/bin/AnnotSV -genomeBuild GRCh37 -outputDir CNV/gatk/{params.sample} -outputFile CNV/gatk/{params.sample}/{params.sample}.intervals.annotations -SVinputFile {output.bed1} -svtBEDcol 5 -vcfFiles {input.vcf} -vcfSamples {params.sample} -bedtools /sysapps/cluster/software/BEDTools/2.27.1/bedtools
           $ANNOTSV/bin/AnnotSV -genomeBuild GRCh37 -outputDir CNV/gatk/{params.sample} -outputFile CNV/gatk/{params.sample}/{params.sample}.segments.annotations -SVinputFile {output.bed2} -svtBEDcol 5 -vcfFiles {input.vcf} -vcfSamples {params.sample} -bedtools /sysapps/cluster/software/BEDTools/2.27.1/bedtools
           perl /hpcdata/dir/software/filterCNVs.pl {output.annot1} {output.candidates}"""

###
###	Collapse CNV Files
###
rule fix_cnv:
	input:
		candidates = join(dir_renamed, "CNV", "gatk", "{newID}", "{newID}.candidate.cnvs")
	output:
		fixed_cnv = join(dir_renamed, "CNV", "gatk", "{newID}", "{newID}_cnv.txt")
	params:
		sample = "{newID}"
	shell:
		"""set +u
		module load anaconda3/5.3.0
		python /hpcdata/dir/SCRIPTS/cnv_collapse_ucsc.py -i {input.candidates} -o CNV/gatk/{params.sample}
		"""

###
### Identify inbreeding outliers
###
rule inbreeding:
    input: 
        vcf = join(dir_renamed, "VCF", batch_name + ".vcf.gz"),
    output: 
        knownsvcf = temp(join(dir_renamed, "inbreeding", "known.sites.vcf")),
        filtvcf = temp(join(dir_renamed, "inbreeding", "filtered.known.sites.recode.vcf.gz")),
        plota = join(dir_renamed, "inbreeding", "Heterozygous_to_Homozygous_Ratio_mqc.png"),
        plotb = join(dir_renamed, "inbreeding", "Mean_Homozygous_Tract_Length_mqc.png"),
    params: 
        batch = batch_name, 
        rname = "inbreeding"
    shell: 
        """set +u
           module load GATK/3.8.1-Java-1.8.0_92
           mkdir -p inbreeding
           java -Djava.io.tmpdir=inbreeding/tmp -jar $EBROOTGATK/GenomeAnalysisTK.jar -T SelectVariants -R /hpcdata/dir/CIDR_DATA_RENAMED/references/human_g1k_v37_decoy.fasta -L /hpcdata/dir/CIDR_DATA_RENAMED/references/exome_targets.bed -V {input.vcf} -o {output.knownsvcf} --concordance /hpcdata/dir/software/resources/1k_genomes_phase3_autosomes.vcf.gz
           module purge
           module load uge
           module load vcftools/0.1.15-goolf-1.7.20-Perl-5.22.2
           vcftools --vcf {output.knownsvcf} --remove-indels --min-alleles 2 --max-alleles 2 --max-missing 1 --recode --recode-INFO-all --out inbreeding/filtered.known.sites
           module purge
           module load uge
           module load tabix
           bgzip inbreeding/filtered.known.sites.recode.vcf
           tabix -p vcf inbreeding/filtered.known.sites.recode.vcf.gz
           module purge
           module load uge
           module load picard/2.17.6
           java -jar /sysapps/cluster/software/picard/2.17.6/picard.jar CollectVariantCallingMetrics INPUT=inbreeding/filtered.known.sites.recode.vcf.gz OUTPUT=inbreeding/picardMetrics DBSNP=/hpcdata/dir/software/resources/00-All.vcf.gz THREAD_COUNT=8
           module purge
           module load uge
           module load plink/1.90-x86_64-beta
           plink --noweb --recode12 --snps-only --out inbreeding/filtered.known.sites --vcf inbreeding/filtered.known.sites.recode.vcf.gz
           module purge
           module load uge
           /hpcdata/dir/software/plink-1.07-x86_64/plink --file inbreeding/filtered.known.sites --noweb --homozyg --out inbreeding/ROH
           module purge
           module load uge
           module load R
           Rscript /hpcdata/dir/software/inbreedingPlot.R"""

##
## Rename the cram files using gatk and a sample mapping file and convert to bam
##
rule bams:
    input: 
        bam = lambda w: expand(join(dir_rawdata, seqdir, "{oldID}." + seqfile), oldID = dict_CIDR[w.newID])
    output:
        bam = join(dir_renamed, "BAM", "{newID}.bam") 
    params: 
        rname = "BAMS_rename",
        oldsearch = lambda w: dict_CIDR[w.newID]
    shell:
        """set +u
        export TODAY=`date +"%Y%m%d"`
        module load samtools
        samtools view -H {input.bam} | sed -e 's/{params.oldsearch}/{wildcards.newID}/g' > {output.bam}.sam
        samtools view -b -o {output.bam}.tmp {input.bam}
        samtools reheader {output.bam}.sam {output.bam}.tmp  > {output.bam}
        rm {output.bam}.sam {output.bam}.tmp
        samtools index {output.bam}"""

###
### Rename the VCF file
###
### SUE: need to create one full vcf with tbi, and one batch specific vcf
rule vcf:
    input: 
        vcf = VCF

    output:
        vcf = join(dir_renamed, "VCF", batch_name + ".vcf.gz"),
        vci = join(dir_renamed, "VCF", batch_name + ".vcf.gz.tbi"),
        mapa = temp(join(dir_renamed, "vcf_mapping_a.txt")),
        mapb = temp(join(dir_renamed, "vcf_mapping_b.txt")),
        first = temp(join(dir_renamed, "VCF", "first.vcf")),

    params:
        rname = "VCF_rename",
        key = dir_renamed + "/masterkey_batch" + batch_number + ".txt",
        vcf_notgz = temp(join(dir_renamed, "VCF", batch_name + ".vcf")),

    shell:
        """set +u
        export TODAY=`date +"%Y%m%d"`
        module load bcftools/1.9-goolf-1.7.20
        tail -n +2 {params.key} | awk '{{print $3 "\\t" $2}}' > {output.mapa}
        cut -f 1 {output.mapa} > {output.mapb}
        bcftools view -S {output.mapb} --force-samples {input.vcf} > {output.first}
        bcftools reheader -s {output.mapa} -o {params.vcf_notgz} {output.first}
        bgzip {params.vcf_notgz}
        tabix -p vcf {output.vcf}"""
###
### Rename the QC files
### 
rule qc:
    input:    
        target = lambda w: [join(dir_rawdata, "Gene_Exonic_Cvg_Reports", "TARGET",  dict_CIDR[w.newID] + ".TARGET_BED.sample_{fname}.csv")],
        ucsc = lambda w: [join(dir_rawdata, "Gene_Exonic_Cvg_Reports", "UCSC", dict_CIDR[w.newID] + ".UCSC_CODING.sample_{fname}.csv")]
    output: 
        target = join(dir_renamed, "QC", "TARGET", "{newID}.TARGET.sample_{fname}.csv"),
        ucsc = join(dir_renamed, "QC", "UCSC", "{newID}.UCSC.sample_{fname}.csv") 
    params:
        rname = "QC_rename",
        oldsearch = lambda w: dict_CIDR[w.newID],
    shell: 
        """set +u
        export TODAY=`date +"%Y%m%d"`
        sed -e 's/{params.oldsearch}/{wildcards.newID}/g' {input.target} > {output.target}
        sed -e 's/{params.oldsearch}/{wildcards.newID}/g' {input.ucsc} > {output.ucsc}"""

###
### Create new pedigrees_updated directory and refresh all pedigree files
###
rule peds:
    output:
        # should create a list of ped files, but will die if any fail, so only need to test for last
        last_ped = join(dir_peds, todays_date, "seqr_ped_batch" + last_batch + ".txt")
    params:
        rname = "Peds_refresh",
        dir_peds_today = join(dir_peds, todays_date),
        last_batch = last_batch
    shell:
        """set +u
        export TODAY=`date +"%Y%m%d"`
        module load python
        mkdir -p {params.dir_peds_today}
        cd {params.dir_peds_today}
        /hpcdata/dir/SCRIPTS/rerun_old_peds.sh {params.last_batch}"""

##
## Calculate HLA for all BAM files
##
rule hla:
    input: 
        bam = join(dir_renamed, "BAM", "{newID}.bam"),
    output: 
        hla = join(dir_renamed, "HLA", "{newID}", "hla", "R1_bestguess_G.txt"),
    params: 
        rname = "hla",
        hladir = join(dir_renamed, "HLA")
    shell: 
        """set +u
        export TODAY=`date +"%Y%m%d"`
        module load HLA-LA
        module load samtools
        mkdir -p HLA
        cd {dir_hla_master}
        ./HLA-LA.pl --BAM {input.bam} --graph ../../../../../../hpcdata/dir/CIDR_DATA_RENAMED/references/graphs/PRG_MHC_GRCh38_withIMGT  --sampleID {wildcards.newID} --maxThreads 7 --picard_sam2fastq_bin /sysapps/cluster/software/picardtools/1.119/SamToFastq.jar --workingDir {params.hladir}"""

