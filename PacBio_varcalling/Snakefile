#################################
#snakefile for implementing PacBio variant calling pipeline
#Cihan Oguz, cihan.oguz@nih.gov
#NIAID Collaborative Bioinformatics Resource (NCBR)
#July 19, 2019
################################
################################

DATA_SAMPLES = ["lbc65", "lbc66", "lbc67","lbc68"]
ref_fasta = "/data/NCBR/references/p_falciparium_3D7ensembl/Plasmodium_falciparum.EPr1.dna.toplevel.fa"
gff_file = "/data/NCBR/references/p_falciparium_3D7ensembl/Plasmodium_falciparum.EPr1.44.sorted.gff3.gz"


rule all:
    input:
        expand("raw_subreads/{dataset}.raw.fastq", dataset=DATA_SAMPLES),
        expand("nanoplot_raw/{dataset}/HistogramReadlength_{dataset}.pdf",dataset=DATA_SAMPLES),
        expand("nanoplot_raw/{dataset}/HistogramReadlength_mqc_{dataset}.png",dataset=DATA_SAMPLES),
        expand("raw_subreads/{dataset}.raw.fastqc.html",dataset=DATA_SAMPLES),
        expand("ccs_reads/{dataset}.ccs.report.txt",dataset=DATA_SAMPLES),
        expand("ccs_reads/{dataset}.ccs.bam",dataset=DATA_SAMPLES),
        expand("ccs_reads/{dataset}.ccs.fastq",dataset=DATA_SAMPLES),
        expand("nanoplot_ccs/{dataset}/{dataset}LengthvsQualityScatterPlot_dot.pdf",dataset=DATA_SAMPLES),
        expand("nanoplot_ccs/{dataset}/{dataset}LengthvsQualityScatterPlot_mqc.png",dataset=DATA_SAMPLES),
        expand("ccs_fastqc/{dataset}.ccs_fastqc.html",dataset=DATA_SAMPLES),
        expand("{dataset}.realign.bam",dataset=DATA_SAMPLES),
        expand("qualimap/{dataset}/qualimapReport.html",dataset=DATA_SAMPLES),
        expand("{dataset}.flagstat",dataset=DATA_SAMPLES),
        expand("{dataset}.picardMetrics",dataset=DATA_SAMPLES),
        expand("{dataset}.stats.txt",dataset=DATA_SAMPLES),
        expand("{dataset}.gvcf",dataset=DATA_SAMPLES),
        expand("{dataset}.calls.bam",dataset=DATA_SAMPLES)


#rule 1
rule gener_raw_subreads:
    input:
        "/data/NCBR/rawdata/NCBR-77/raw_reads/{dataset}.bam"
    output:
        "raw_subreads/{dataset}.raw.fastq"
    shell:
        """mkdir -p raw_subreads
        module load samtools
        samtools fastq {input} > {output}"""

#rule 2
rule nano_raw_subreads_1:
    input:
        "raw_subreads/{dataset}.raw.fastq"
    output:
        "nanoplot_raw/{dataset}/HistogramReadlength_{dataset}.pdf"
    params:
        directory = DATA_SAMPLES,
    shell:
        """source /data/NCBR/rawdata/NCBR-56/ccs_bams/conda/etc/profile.d/conda.sh
        conda activate base
        mkdir -p nanoplot_raw
        mkdir -p nanoplot_raw/{params.directory}
        NanoPlot -t 12 -o nanoplot_raw/{params.directory} --prefix {params.directory} --maxlength 21000 --minlength 10 -f pdf --fastq {input}"""

#rule 3
rule nano_raw_subreads_2:
    input:
        "nanoplot_raw/{dataset}/HistogramReadlength_{dataset}.pdf"
    output:
        "nanoplot_raw/{dataset}/HistogramReadlength_mqc_{dataset}.png"
    params:
        directory = DATA_SAMPLES,
    shell:
        """module load R
        Rscript /data/NCBR/apps/pdf2png.R {input} {output}"""

##fastqc on raw subreads
#rule 4
rule fastqc_raw_subreads:
    input:
        "raw_subreads/{dataset}.raw.fastq"
    output:
        "raw_subreads/{dataset}.raw.fastqc.html"
    shell:
        """module load fastqc
        mkdir -p raw_fastqc
        fastqc -o raw_fastqc -f fastq --threads 12 --extract {input}"""

##HERE'S THE FORK!!! generate CCS reads if there aren't any in the rawdata/ccs_reads directory
#rule 5
rule generate_ccs_reads:
    input:
        "/data/NCBR/rawdata/NCBR-77/raw_reads/{dataset}.bam"
        #"/data/NCBR/rawdata/NCBR-77/raw_read_bams/{dataset}.bam"
    output:
        report="ccs_reads/{dataset}.ccs.report.txt",
        bam="ccs_reads/{dataset}.ccs.bam"
    shell:
        """source /data/NCBR/rawdata/NCBR-56/ccs_bams/conda/etc/profile.d/conda.sh
        conda activate base
        mkdir -p ccs_reads
        ccs --minPredictedAccuracy 0.99 -j 32 --reportFile {output.report} {input} {output.bam}"""

#rule 6
#IN FORK...extract fastq files
rule fastq_ccs_reads:
    input:
        "ccs_reads/{dataset}.ccs.bam"
    output:
        "ccs_reads/{dataset}.ccs.fastq"
    shell:
        """module load samtools
        mkdir -p ccs_reads
        samtools fastq {input} > {output}"""


##rule 7
rule nano_ccs_reads_1:
    input:
        "ccs_reads/{dataset}.ccs.fastq"
    output:
        "nanoplot_ccs/{dataset}/{dataset}LengthvsQualityScatterPlot_dot.pdf"
    params:
        directory = DATA_SAMPLES,
    shell:
        """source /data/NCBR/rawdata/NCBR-56/ccs_bams/conda/etc/profile.d/conda.sh
        conda activate base
        mkdir -p nanoplot_ccs
        mkdir -p nanoplot_ccs/{params.directory}
        NanoPlot -t 12 -o nanoplot_ccs/{params.directory} --prefix {params.directory} --maxlength 21000 --minlength 10 -f pdf --fastq {input}
        """

#rule 8
rule nano_ccs_reads_2:
    input:
        "nanoplot_ccs/{dataset}/{dataset}LengthvsQualityScatterPlot_dot.pdf"
    output:
        "nanoplot_ccs/{dataset}/{dataset}LengthvsQualityScatterPlot_mqc.png"
    params:
        directory = DATA_SAMPLES,
    shell:
        """module load R
        Rscript /data/NCBR/apps/pdf2png.R {input} {output}"""


##fastqc on ccs reads
#rule 9
rule fastqc_ccs_reads:
    input:
        "ccs_reads/{dataset}.ccs.fastq"
    output:
        "ccs_fastqc/{dataset}.ccs_fastqc.html"
    shell:
        """module load fastqc
        mkdir -p ccs_fastqc
        fastqc -o ccs_fastqc -f fastq --threads 8 --extract {input}"""



##ccs read reference alignment
#rule 10
rule ccs_read_ref_align:
    input:
        "ccs_reads/{dataset}.ccs.fastq"
    output:
        "{dataset}.sort.bam"
    params:
        ref = ref_fasta,
    shell:
        """source /data/NCBR/rawdata/NCBR-56/ccs_bams/conda/etc/profile.d/conda.sh
        conda activate base
        pbmm2 align {params.directory} {input} {output} --preset CCS --sort -j 12"""
#--sort already generating a bam.bai

# ##Add read groups to alignment BAM file
# #rule 11
rule ccs_readgroup_to_align_bam_1:
    input:
        "{dataset}.sort.bam"
    output:
        bai="{dataset}.sort.bam.bai",
        rehead_bam="{dataset}.sort.rehead.bam"
    params:
        directory =  DATA_SAMPLES,
    shell:
        """module load samtools
        samtools index {input}
        module load picard
        java -Xmx24g -jar $PICARDJARPATH/picard.jar AddOrReplaceReadGroups I={input} O={output.rehead_bam} Validation_Stringency=LENIENT RGID=1 RGLB={params.directory} RGPL=Sequel RGPU=AAAAAA RGSM={params.directory}
#         """
#
#
# #rule 12
rule ccs_readgroup_to_align_bam_2:
    input:
        "{dataset}.sort.rehead.bam"
    output:
        "{dataset}.sort.rehead.bam.bai",
    params:
        directory =  DATA_SAMPLES,
    shell:
        """module load samtools
        samtools index {input}"""

rule realign:
    input:
        bam="{dataset}.sort.rehead.bam",
        index="{dataset}.sort.rehead.bam.bai"
    output:
        bam="{dataset}.realign.bam",
        int="{dataset}.intervals",
    params:
        directory =  DATA_SAMPLES,ref = ref_fasta,
    shell:
        """
        module load GATK/3.8-0
        java -Xmx48g -Djava.io.tmpdir=/lscratch/$SLURM_JOBID -jar $GATK_JAR -T RealignerTargetCreator -I {input.bam} -R {params.ref} -o {output.int}
        java -Xmx48g -Djava.io.tmpdir=/lscratch/$SLURM_JOBID -jar $GATK_JAR -T IndelRealigner -R {params.ref} -I {input.bam} --use_jdk_inflater --use_jdk_deflater -targetIntervals {output.int} -o {output.bam}
        """

rule bam_recal:
    input:
        bam="{dataset}.realign.bam",
    output:
        bam="{dataset}.recal.bam",
        re="{dataset}.recal.txt",
    params:
        directory =  DATA_SAMPLES,ref = ref_fasta,
    shell:
        """
        module load GATK/4.1.2.0
        gatk BaseRecalibrator -I {input} -R {params.genome} {params.knowns} -O {output.re}
        gatk ApplyBQSR -R {params.genome} -I {input} --bqsr-recal-file {output.re} -o {output.bam}
        """

#
#
#
# #rule 13
# ###Qualimap QC on BAM file
rule qualimap_qc_on_bam:
    input:
        "{dataset}.realign.bam",
    output:
        "qualimap/{dataset}/qualimapReport.html"
    params:
        directory = DATA_SAMPLES,
    shell:
        """mkdir -p qualimap
        mkdir -p qualimap/{params.directory}
        module load qualimap/2.2.1
        unset DISPLAY
        qualimap bamqc --java-mem-size=48G -bam {input} -c -outdir qualimap/{params.directory} -nt 12 -outformat HTML -nw 500 -outfile {output}"""
#
#rule 14
##samtools flagstats
rule samtools_flagstats:
    input:
        "{dataset}.sort.rehead.bam"
    output:
        "{dataset}.flagstat"
    shell:
        """module load samtools
        samtools flagstat {input} > {output}"""


#rule 15
##Picard BAM Metrics
rule picard_bam_metrics:
    input:
        "{dataset}.sort.rehead.bam"
    output:
        "{dataset}.picardMetrics"
    shell:
        """java -Xmx24g -jar $PICARDJARPATH/picard.jar CollectMultipleMetrics R=$REF I={input} O={output} PROGRAM=CollectAlignmentSummaryMetrics PROGRAM=QualityScoreDistribution PROGRAM=MeanQualityByCycle PROGRAM=CollectBaseDistributionByCycle PROGRAM=CollectGcBiasMetrics PROGRAM=CollectSequencingArtifactMetrics PROGRAM=CollectQualityYieldMetrics"""

#rule 16
##samtools stats on BAM files
rule samtools_stats_on_bam_files:
    input:
        "{dataset}.sort.rehead.bam"
    output:
        "{dataset}.stats.txt"
    params:
        directory = ref_fasta,
    shell:
        """module load samtools
        samtools stats --ref-seq {params.directory} {input} > {output}"""


#rule 17
##Generating gVCFs/HaplotypeCaller
rule gvcf_haplo:
    input:
        "{dataset}.realign.bam"
    output:
        gvcf="{dataset}.gvcf",
        calls_bam="{dataset}.calls.bam"
    params:
        ref = ref_fasta,
    shell:
        """module load GATK/4.1.2.0
        gatk HaplotypeCaller -R {params.ref} -I {input} -O {output.gvcf} --ploidy 1 --pcr-indel-model AGGRESSIVE -bamout {output.calls_bam} -ERC GVCF --minimum-mapping-quality 60 --annotation-group AS_StandardAnnotation --annotation-group StandardAnnotation"""

##Generating gVCFs/HaplotypeCaller
rule joint_haplo:
    input: expand("{dataset}.realign.bam")
    output:
        vcf="joint_vcfs/joint_raw.vcf",
    params:
        ref = ref_fasta,
    shell:
        fl=os.popen("ls *.realign.bam").read().split()      
        var=" -I "+" -I ".join(fl)
        cmd="mkdir -p joint_vcfs; module load GATK/4.1.2.0; gatk HaplotypeCaller -R {params.ref} -O {output.vcf} --ploidy 1 --pcr-indel-model AGGRESSIVE --minimum-mapping-quality 60 --annotation-group AS_StandardAnnotation --annotation-group StandardAnnotation"+var
        print(cmd)
        shell(cmd)

##Combining gVCFs
rule combo_gvcfs:
    input: expand("{dataset}.gvcf")
    output:
        gvcf="merged.gvcf",
    params:
        ref = ref_fasta,
    shell:
        fl=os.popen("ls *.gvcf").read().split()
        var=" --variant "+" --variant ".join(fl)
        cmd="module load GATK/4.1.2.0; gatk CombineGVCFs -R {params.ref} -O {output.gvcf} --annotation-group AS_StandardAnnotation --annotation-group StandardAnnotation"+var
        print(cmd)
        shell(cmd)

##Genotype gVCFs
rule genotyping:
    input: gvcf="merged.gvcf",
    output:
        vcf="raw_variants.vcf",
    params:
        ref = ref_fasta,
    shell:
        cmd="module load GATK/4.1.2.0; gatk GenotypeGVCFs -R {params.ref} -O {output.vcf} --annotation-group AS_StandardAnnotation --annotation-group StandardAnnotation"
        print(cmd)
        shell(cmd)

##Filter VCFs
rule filter:
    input: vcf="raw_variants.vcf",
    output:
        snps="snps.vcf",
        shortindels="1bpindels.vcf",
        indels="indels.vcf",
        flagsnps="snps.flagged.vcf",
        flagshort="1bpindels.flagged.vcf",
        flagindels="indels.flagged.vcf",
        flagmerged="merged.flagged.vcf",
        filtered="filtered.vcf",
        bcftools="filtered.bcftools",
        vep="filtered.vep",
#        snpeffcsv=""filtered.snpeff.csv"
#        snpeffstats=""filtered.snpeff.html"
    params:
        ref = ref_fasta,gff=gff_file
    shell:
        """
        module load GATK/4.1.2.0
        gatk SelectVariants -R {params.ref} --variant {input.vcf} -O {output.snps} --select-type-to-include SNP --exclude-filtered
        gatk SelectVariants -R {params.ref} --variant {input.vcf} --select-type-to-include INDEL --exclude-filtered -O {output.shortindels} --max-indel-size 1 --min-indel-size 1
        gatk SelectVariants -R {params.ref} --variant {input.vcf} --select-type-to-include INDEL --exclude-filtered -O {output.indels} --min-indel-size 2
        gatk VariantFiltration -R {params.ref} --variant {output.snps} --filter-expression "AS_QD < 2.0" --filter-name "my_snp_filter" -O {output.flagsnps}
        gatk VariantFiltration -R {params.ref} --variant {output.shortindels} --filter-expression "AS_QD < 5.0" --filter-name "my_shortindel_filter" -O {output.flagshort}
        gatk VariantFiltration -R {params.ref} --variant {output.indels} --filter-expression "AS_QD < 2.0" --filter-name "my_indel_filter" -O {output.flagindels}
        gatk MergeVcfs -I={output.flagsnps} -I={output.flagshort} -I={output.flagindels} -O={output.flagmerged}
        gatk SelectVariants -R {params.ref} -V {output.flagmerged} --exclude-filtered -O {output.filtered}
        module load samtools
        bcftools stats -F {params.ref} {output.filtered} > {output.bcftools}
        module load VEP
        vep -sf filtered.vepstats.html --fasta {params.ref} --gff {params.gff} --tab -i {output.filtered} --format vcf -o {output.vep} --pick
#        java -jar /data/lackjb/snpEff/snpEff.jar -canon -csvStats {output.snpeffcsv} -stats {output.snpeffstats} -o bedAnn {params.species} joint_variants.filtered.vcf > joint_variants.filtered.annotations.bed
        """

##Filter joint VCFs
rule filter_joint:
    input: vcf="joint_vcfs/joint_raw.vcf",
    output:
        snps="joint_vcfs/snps.vcf",
        shortindels="joint_vcfs/1bpindels.vcf",
        indels="joint_vcfs/indels.vcf",
        flagsnps="joint_vcfs/snps.flagged.vcf",
        flagshort="joint_vcfs/1bpindels.flagged.vcf",
        flagindels="joint_vcfs/indels.flagged.vcf",
        flagmerged="joint_vcfs/merged.flagged.vcf",
        filtered="joint_vcfs/filtered.vcf",
        bcftools="joint_vcfs/filtered.bcftools",
        vep="joint_vcfs/filtered.vep",
    params:
        ref = ref_fasta,gff=gff_file
    shell:
        """
        module load GATK/4.1.2.0
        gatk SelectVariants -R {params.ref} --variant {input.vcf} -O {output.snps} --select-type-to-include SNP --exclude-filtered
        gatk SelectVariants -R {params.ref} --variant {input.vcf} --select-type-to-include INDEL --exclude-filtered -O {output.shortindels} --max-indel-size 1 --min-indel-size 1
        gatk SelectVariants -R {params.ref} --variant {input.vcf} --select-type-to-include INDEL --exclude-filtered -O {output.indels} --min-indel-size 2
        gatk VariantFiltration -R {params.ref} --variant {output.snps} --filter-expression "AS_QD < 2.0" --filter-name "my_snp_filter" -O {output.flagsnps}
        gatk VariantFiltration -R {params.ref} --variant {output.shortindels} --filter-expression "AS_QD < 5.0" --filter-name "my_shortindel_filter" -O {output.flagshort}
        gatk VariantFiltration -R {params.ref} --variant {output.indels} --filter-expression "AS_QD < 2.0" --filter-name "my_indel_filter" -O {output.flagindels}
        gatk MergeVcfs -I={output.flagsnps} -I={output.flagshort} -I={output.flagindels} -O={output.flagmerged}
        gatk SelectVariants -R {params.ref} -V {output.flagmerged} --exclude-filtered -O {output.filtered}
        module load samtools
        bcftools stats -F {params.ref} {output.filtered} > {output.bcftools}
        module load VEP
        vep -sf joint_vcfs/filtered.vepstats.html --fasta {params.ref} --gff {params.gff} --tab -i {output.filtered} --format vcf -o {output.vep} --pick
#        java -jar /data/lackjb/snpEff/snpEff.jar -canon -csvStats {output.snpeffcsv} -stats {output.snpeffstats} -o bedAnn {params.species} joint_variants.filtered.vcf > joint_variants.filtered.annotations.bed
        """

##Extract sample variants
rule extract_sample_variants:
    input:
        "filtered.vcf",
    output:
        vcf="sample_vcfs/{dataset}.vcf",
        bcftools="sample_vcfs/{dataset}.bcftools",
        vep="sample_vcfs/{dataset}.vep",
    params:
        ref = ref_fasta,sample={dataset},gff=gff_file
    shell:
        """
        mkdir -p sample_vcfs
        module load GATK/4.1.2.0
        gatk SelectVariants -R {params.ref} --variant {input} -O {output.vcf} -sn {params.dataset} --exclude-non-variants
        module load samtools
        bcftools stats -F {params.ref} {output.vcf} > {output.bcftools}
        module load VEP
        vep -sf sample_vcfs/{params.sample}.vepstats.html --fasta {params.ref} --gff {params.gff} --tab -i {input} --format vcf -o {output.vep} --pick"""
